---
layout:     post
title:      "spark学习笔记"
subtitle:   " \"\""
date:       2017-11-17 12:00:00
author:     "MYC"
header-img: "img/post-bg-2017.jpg"
catalog: true
tags:
    - 分布式
    - 大数据处理框架
    - spark
---

## spark

笔记：

三种集群部署方案： Standalone, Mesos, Yarn，其中 Standalone 为spark本身提供的集群模式。

Apache Hadoop YARN （Yet Another Resource Negotiator，另一种资源协调者）是一种新的 Hadoop 资源管理器，所以根据这个定义，其他两个应该跟yarn是一个类型的东西，可以理解为一个集群的资源管理器。

maven好像是一个相当于开发软件的东西，可以进行项目管理包括编译，测试等。

RDD（resilient distributed dataset）:spark的数据抽象，spark计算操作核心。

shuffle：将具有相同key但分布在不同节点的成员聚合到一个节点，以便操作。

stage：shuffle dependency RDD创建stage，其他不创建。聚合操作时依赖所有分区节点，DAG调度时相同节点task计算合并为一个stage。

DAG：

hadoop结构：MapReduce和HDFS。

hive：在hdfs中抽象出的sql风格层，可以连接数据库，并提供给hadoop，不需要MR程序，直接数据库list概念管理数据。

HBase：hadoop非关系型数据库，场景：数据仓库。

zookeeper：提供分布式应用程序协调服务的程序。

YARN：将资源调度从MR范式中分离出来的一个调度系统，spark中还有Mesos、standalone。

Map Reduce：map->拆分任务、reduce->合并任务。

spark支持：SQL、spark streaming、mlib、Graphx。

![](http://ox0pxbncm.bkt.clouddn.com/17-11-17/555438.jpg)

spark集群结构：

​	Spark集群基于Zookeeper的HA：spark、hdfs、yarn、zookeeper。

​	spark负责计算，现在的hadoop MR和hdfs是分开的，所以可以直接使用hadoop的hdfs存储数据。

![](http://ox0pxbncm.bkt.clouddn.com/17-11-17/39175138.jpg)

### spark工作机制

​	sparkcontext工作模式，driver程序就是spark程序，driver包含sparkcontext。

![](http://ox0pxbncm.bkt.clouddn.com/17-11-17/6674755.jpg)

​	standalone：最简单的一种集群，只支持FIFO。

​	hadoop YARN：动态资源管理，多用户场景，多集群同时部署。

​	apache Mesos：专门分布式系统资源管理，弹性管理。

### spark调度机制

静态分配：一次性分配所有资源

动态分配：不断调整分配资源

动态分配的粒度是执行器。



### spark集群注意事项

spark slave靠近HDFS或HBase，减少网络开销。

spark slave、HDFS datanode、YARN nodemanager部署在相同机器上。

spark节点内存需要较大，因为RDD是缓存在内存中的，数据量较大的情况下对内存需求很高。

shuffle的操作比如ByKey的操作对资源占用很高，特别是网络。

### RDD

spark数据核心，是放入内存的。

RDD生成方式：

1. driver程序数据集生成sc.paralise(data)，data可以是seq、array、list
2. 外部数据集生成，文件共享系统、HDFS、HBase。

RDD操作：

1. transformation：计算生成新的RDD（flatMap、map、reduceByKey）
2. Action：返回结果到driver程序，RDD计算结束

spark严重依赖函数类型参数。

RDD不能嵌套调用。

### spark streaming

可以进行实时计算

数据来源支持Kafka、flume、twitter、zeroMQ，TCP socket等

使用map、reduce、join、window

结果可写入文件系统、界面展示

可以使用spark sql、dataframe、ML、图计算

![](https://i.loli.net/2017/11/17/5a0e9907e54ab.png)

![](https://i.loli.net/2017/11/17/5a0e991e36f1c.png)

streaming数据抽象：Dstream，内部是RDD的列表。

支持语言：python、java、scala。

streaming使用方法和spark类似，只是输出可能不太一样，其他都是对用户透明的。

Dstream三种输入：

1. 基本型：API直接提供（文件系统、socket、akka actor）
2. 高级型：额外的库实现：Kafka、flume等，需要设置编译依赖，打包
3. 自定义型：子ui信哪个制定编码实现

Dstream操作：

1. transformation：类似RDD的
2. output：类似Action，输出Dstream至外部系统，比如文件系统，数据库，BI报表。

滑动窗口

​	窗口长度

​	窗口区间

运行spark streaming word count：

```shell
/myest/spark-2.2.0-bin-hadoop2.7/bin/spark-submit --class StreamingWordCount --master spark://192.168.5.132:7077 --executor-memory 1g --num-executors 3 streamingwordcount_2.11-1.0.jar 2>/dev/null
```

可以到master:4040查看streaming的运行报表。

![](https://i.loli.net/2017/11/17/5a0e9c5ace3b8.png)

### spark sql

语法基本和hive类似，配置方法也一致。

可以通过spark sql管理很多类型的数据，所以取代了hive在spark中使用。

这个东西比较玄学，本来想配置spark sql和MySQL连接，但是一直被access deny，修改用户权限也不行，写了个java jdbc直接MySQL脚本一点事也没有，搞了很久，没搞出来。。

### Spark集群基于Zookeeper的HA搭建

zookeeper的用处就是竞选出一个master节点，要求节点数为奇数。

下载java、scala，注意java、scala的版本要和spark的版本一致，这个可以到spark官网看看，比如我的2.2.0版本需要Scala2.11.8，jdk1.8.*的，这个时候最好不要用其他版本的，会出现很多问题的。

这里配置了三个节点，虚拟机配的，建议每个虚拟机配置2g内存。

创建三个虚拟机，修改host：

```shell
192.168.1.141 master
192.168.1.142 slave1
192.168.1.137 slave2
```

虚拟机之间配置使用ssh无密码连接：

```shell
sudo apt-get install openssh-server
ssh-keygen
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
```

把**公钥**"authorized_keys"复制**所****有**的Slave机器上

```shell
scp -r authorized_keys username@slave1:/home/username
scp -r authorized_keys username@slave2:/home/username
//移动authorized_keys到.ssh目录下
```

#### 下载配置zookeeper

[zookeeper](http://apache.claz.org/zookeeper/zookeeper-3.4.5/zookeeper-3.4.5.tar.gz)

配置环境变量/etc/profile,下列代码加入文件最后。（首行、尾行是shell命令）

``` shell
vim /etc/profile
export ZOOKEEPER_HOME=/myest/zookeeper-3.4.10
export PATH=$PATH:$ZOOKEEPER_HOME/bin
source /etc/profile
```

zookeeper配置：

zookeeper目录下添加如下data、log文件夹

进到conf目录下，把zoo_sample.cfg修改成zoo.cfg（这一步是必须的，否则zookeeper不认识zoo_sample.cfg），并添加如下内容：

``` shell
dataDir=/root/install/zookeeper-3.4.5/data
dataLogDir=/root/install/zookeeper-3.4.5/logs
server.0= master:2888:3888
server.1= slave1:2888:3888
server.2= slave2:2888:3888
```

在data文件夹下创建myid文件，按照上面server.%具体数字写入到myid。比如master下写入0。

将zookeeper scp到每个slave下，只修改myid，然后配置环境变量。

每台机器运行zkServer.sh start

然后运行zkServer.sh status查看状态，显示如下说明正常。

![](http://ox0pxbncm.bkt.clouddn.com/17-11-17/71962979.jpg)

如果显示Error contacting service. It is probably not running.

可能是host配置的问题，比如我的就是host中配置如下，如果将#去掉，zookeeper将会追踪master到127.0.1.1，这个时候就不能和其他节点通信，应该是本地回环，所以不能与外界通信，因此注释那一行，就能正常运行。

![](http://ox0pxbncm.bkt.clouddn.com/17-11-17/79614057.jpg)

#### 下载配置spark

[官网](http://spark.apache.org/downloads.html)下载

spark配置：

配置环境变量/etc/profile

```shell
export SPARK_HOME=/myest/spark-2.2.0-bin-hadoop2.7 
```

配置spark-env.sh

```shell
export JAVA_HOME=/myest/jdk1.8.0_151
export SCALA_HOME=/myest/scala-2.12.1
export HADOOP_HOME=/myest/hadoop-2.7.4
export HADOOP_CONF_DIR=/myest/hadoop-2.7.4/etc/hadoop
export SPARK_DAEMON_JAVA_OPTS="-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark    .deploy.zookeeper.url=master:2181,slave1:2181,slave2:2181"
```

最后一步配置spark基于zookeeper的ha的关键步骤。

配置slaves

```
master
slave1
slave2
```
#### 下载配置hadoop

[官网](http://hadoop.apache.org/releases.html)下载，选择binary版

spark配置：

配置环境变量/etc/profile

```shell
export HADOOP_HOME=/myest/hadoop-2.7.4
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```

配置hadoop-env.sh

```shell
export JAVA_HOME=/myest/jdk1.8.0_151
export HADOOP_PREFIX=/myest/hadoop-2.7.4
```

配置core-site.xml

```xml
<configuration>
    <property>
         <name>fs.defaultFS</name>
             <value>hdfs://master:9000</value>
        </property>
        <property>
             <name>hadoop.tmp.dir</name>
              <value>/myest/hadoop-2.7.4/tmp</value>
        </property>
</configuration> 
```

配置hdfs-site.xml

```xml
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>3</value>
    </property>
</configuration>
```

配置yarn-env.sh

```shell
export JAVA_HOME=/myest/jdk1.8.0_151
```

配置yarn-site.xml

```xml
<configuration>
<!-- Site specific YARN configuration properties -->
     <property>
         <name>yarn.nodemanager.aux-services</name>
         <value>mapreduce_shuffle</value>
     </property>
     <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>master</value>
     </property>
</configuration> 
```
#### 启动验证

启动zookeeper（上述说了）

启动hadoop

start-dfs.sh或者直接start-all.sh

最简单的验证方法是在master:50070端口查看，看到live dnodes为2，说明有两个datanode。也可以用jps看有没有后台任务

![](http://ox0pxbncm.bkt.clouddn.com/17-11-17/83243491.jpg)

启动spark

直接start-all.sh

如果报错，检查一下自己的java、scala版本，很有可能是这两个版本的问题。

访问master:8080，查看是否有如下workers存在，master节点也存在一个worker，slave节点各一个，这里可能是开了hadoop的原因还显示了三个unknown节点。

![](http://ox0pxbncm.bkt.clouddn.com/17-11-17/87881838.jpg)

验证集群是否凑效：

```shell
/myest/spark-2.2.0-bin-hadoop2.7/bin/spark-submit --class WordCount --master spark://192.168.5.132:7077 --executor-memory 1g --num-executors 3 wordcount_2.11-1.0.jar 2>/dev/null
```

这里我自己打包了一个wordcount程序，也可以用官方示例sparkPi测试是否运行，可以到master:8080看程序的运行状态。

注意搭建的时候分配内存需要充足，2g最好，不然可能直接挂掉。

### 提交作业到spark集群

```shell
/myest/spark-2.2.0-bin-hadoop2.7/bin/spark-submit --class StreamingWordCount --master spark://192.168.5.132:7077 --executor-memory 1g --num-executors 3 streamingwordcount_2.11-1.0.jar 2>/dev/null
```

